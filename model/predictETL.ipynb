{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Initializations\" data-toc-modified-id=\"Initializations-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initializations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grab-Latest-Model\" data-toc-modified-id=\"Grab-Latest-Model-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Grab Latest Model</a></span></li></ul></li><li><span><a href=\"#Extract-Data\" data-toc-modified-id=\"Extract-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Extract Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Speed-evaluations\" data-toc-modified-id=\"Speed-evaluations-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Speed evaluations</a></span></li><li><span><a href=\"#Test-Pipeline\" data-toc-modified-id=\"Test-Pipeline-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Test Pipeline</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoping out code needed for prediction pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:37:16.497075Z",
     "start_time": "2023-04-24T20:37:16.396881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:37:16.590549Z",
     "start_time": "2023-04-24T20:37:16.521810Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import discordUtils as du\n",
    "import schema\n",
    "import boto3\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from boto3.dynamodb.conditions import  Key, Attr\n",
    "from pyspark.sql import SparkSession\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import sqlUtils as su\n",
    "\n",
    "os.environ['TZ'] = 'UTC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T20:37:16.713405Z",
     "start_time": "2023-04-24T20:37:16.595489Z"
    }
   },
   "outputs": [],
   "source": [
    "dynamodb_resource = boto3.resource('dynamodb', region_name='us-east-2')\n",
    "\n",
    "cfg_file = utils.findConfig()\n",
    "cfg = utils.parseConfig(cfg_file)\n",
    "\n",
    "spark = (\n",
    "  SparkSession\n",
    "  .builder\n",
    "  .appName('redditData')\n",
    "  .config('spark.driver.extraJavaOptions', '-Duser.timezone=GMT')\n",
    "  .config('spark.executor.extraJavaOptions', '-Duser.timezone=GMT')\n",
    "  .config('spark.sql.session.timeZone', 'UTC')\n",
    "  .config(\"fs.s3a.access.key\", cfg['ACCESSKEY'])\n",
    "  .config(\"fs.s3a.secret.key\", cfg['SECRETKEY'])\n",
    "  .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Latest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T21:16:08.558928Z",
     "start_time": "2023-04-24T21:16:07.904596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest model location: s3a://data-kennethmyers/models/Reddit_LR_model_20230414-061010.sav\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3', region_name='us-east-2')\n",
    "bucketName = 'data-kennethmyers'\n",
    "bucket = s3.Bucket(bucketName)\n",
    "objs = bucket.objects.filter(Prefix='models/Reddit_LR_model_')\n",
    "latestModelLoc = sorted([obj.key for obj in objs])[-1]\n",
    "print(f\"Latest model location: s3a://{bucketName}/{latestModelLoc}\")\n",
    "modelSaveLoc = './pickledModels/latestModel.sav'\n",
    "s3_client = boto3.client('s3', region_name='us-east-2')\n",
    "s3_client.download_file('data-kennethmyers', latestModelLoc, modelSaveLoc)\n",
    "model = pickle.load(open(modelSaveLoc, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed evaluations\n",
    "\n",
    "When I wrote the model ETL process, the data was read to Spark DataFrames so that the process could be extended to distributed systems. During the production predictive ETL process, we don't need as much data, in fact there are typically only a few to predict on. As such, we may not need spark for this process and we can use something lighter. \n",
    "\n",
    "Here I'm going to compare the speed of loading the data to spark vs pandas. We could actually get away with something lighter than pandas (ie. keep it in dictionary format) but pandas can help with loading to sql later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.utcnow()\n",
    "tenMinAgo = now-timedelta(seconds=600)\n",
    "tenMinAgoDate = tenMinAgo.strftime('%Y-%m-%d') \n",
    "tenMinAgoTime = tenMinAgo.strftime('%H:%M:%S') \n",
    "\n",
    "risingTable = dynamodb_resource.Table('rising')\n",
    "\n",
    "postIdQueryResult = risingTable.query(\n",
    "    IndexName='byLoadDate',\n",
    "    KeyConditionExpression=Key('loadDateUTC').eq(tenMinAgoDate) & Key('loadTimeUTC').gte(tenMinAgoTime),\n",
    "    FilterExpression=Attr('timeElapsedMin').eq(60),\n",
    "    ProjectionExpression='postId'\n",
    "  )['Items']\n",
    "postsOfInterest = {res['postId'] for res in postIdQueryResult}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T04:06:56.795442Z",
     "start_time": "2023-04-19T04:06:45.948792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27 s ± 35.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "postIdData = utils.getPostIdSparkDataFrame(spark, risingTable, postsOfInterest, chunkSize=100)\n",
    "pandasTestDf = postIdData.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T04:06:59.037822Z",
     "start_time": "2023-04-19T04:06:58.949103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  loadDateUTC         loadTimeUTC           loadTSUTC   postId subreddit                                                                              title        createdTSUTC  timeElapsedMin  score  numComments  upvoteRatio  numGildings\n",
      "0  2023-04-19 1900-01-01 01:33:21 2023-04-19 01:33:21  12raffr      pics                                           The light through this glass of mint tea 2023-04-19 00:32:35              60     16            3         0.95            0\n",
      "1  2023-04-19 1900-01-01 01:40:21 2023-04-19 01:40:21  12ramm9      pics                                                     They aren’t ready for my Queen 2023-04-19 00:39:54              60     47            4         0.87            0\n",
      "2  2023-04-19 1900-01-01 01:33:21 2023-04-19 01:33:21  12rag30      pics                                                                  Ye olde drag show 2023-04-19 00:33:14              60      1            2         0.54            0\n",
      "3  2023-04-19 1900-01-01 01:30:21 2023-04-19 01:30:21  12racaw      pics  Traveling through the northwest in Washington and came across these wicked trees. 2023-04-19 00:29:39              60      7            3         1.00            0\n",
      "4  2023-04-19 1900-01-01 02:09:21 2023-04-19 02:09:21  12rbf81      pics        Took tons of pictures at the Tulip Festival in WA, this one is my favorite! 2023-04-19 01:09:11              60     17            0         0.95            0\n"
     ]
    }
   ],
   "source": [
    "print(pandasTestDf.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T04:07:01.449281Z",
     "start_time": "2023-04-19T04:07:01.375774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadDateUTC       datetime64[ns]\n",
       "loadTimeUTC       datetime64[ns]\n",
       "loadTSUTC         datetime64[ns]\n",
       "postId                    object\n",
       "subreddit                 object\n",
       "title                     object\n",
       "createdTSUTC      datetime64[ns]\n",
       "timeElapsedMin             int32\n",
       "score                      int32\n",
       "numComments                int32\n",
       "upvoteRatio              float32\n",
       "numGildings                int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandasTestDf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T04:07:12.056074Z",
     "start_time": "2023-04-19T04:07:04.043896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993 ms ± 33.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "postIdData = utils.getPostIdPdDataFrame(risingTable, postsOfInterest, chunkSize=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T04:07:12.164907Z",
     "start_time": "2023-04-19T04:07:12.075458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         createdTSUTC         loadTimeUTC  upvoteRatio  timeElapsedMin  numComments loadDateUTC subreddit  score   postId           loadTSUTC  numGildings                                                                              title\n",
      "0 2023-04-19 00:32:35 1900-01-01 01:33:21         0.95              60            3  2023-04-19      pics     16  12raffr 2023-04-19 01:33:21            0                                           The light through this glass of mint tea\n",
      "1 2023-04-19 00:39:54 1900-01-01 01:40:21         0.87              60            4  2023-04-19      pics     47  12ramm9 2023-04-19 01:40:21            0                                                     They aren’t ready for my Queen\n",
      "2 2023-04-19 00:33:14 1900-01-01 01:33:21         0.54              60            2  2023-04-19      pics      1  12rag30 2023-04-19 01:33:21            0                                                                  Ye olde drag show\n",
      "3 2023-04-19 00:29:39 1900-01-01 01:30:21         1.00              60            3  2023-04-19      pics      7  12racaw 2023-04-19 01:30:21            0  Traveling through the northwest in Washington and came across these wicked trees.\n",
      "4 2023-04-19 01:09:11 1900-01-01 02:09:21         0.95              60            0  2023-04-19      pics     17  12rbf81 2023-04-19 02:09:21            0        Took tons of pictures at the Tulip Festival in WA, this one is my favorite!\n"
     ]
    }
   ],
   "source": [
    "print(postIdData.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T04:07:12.261830Z",
     "start_time": "2023-04-19T04:07:12.183759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadDateUTC       datetime64[ns]\n",
       "loadTimeUTC       datetime64[ns]\n",
       "loadTSUTC         datetime64[ns]\n",
       "postId                    object\n",
       "subreddit                 object\n",
       "title                     object\n",
       "createdTSUTC      datetime64[ns]\n",
       "timeElapsedMin             int32\n",
       "score                      int32\n",
       "numComments                int32\n",
       "upvoteRatio              float32\n",
       "numGildings                int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandasTestDf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many situations, a 20% speed improvement can be significant (ie a streaming setting). We are running periodic batch jobs so it is not especially important but I wanted to demonstrate how changing the process between modeling and predicting can provide improvements. \n",
    "\n",
    "For now, I don't want to rewrite my transformation processes in pandas, so I will continue to use the spark process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T22:05:26.952337Z",
     "start_time": "2023-04-24T22:05:23.276238Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    postId subreddit  title        createdTSUTC  maxScore20m  maxScore21_40m  maxScore41_60m  maxNumComments20m  maxNumComments21_40m  maxNumComments41_60m  maxUpvoteRatio20m  maxUpvoteRatio21_40m  maxUpvoteRatio41_60m  maxNumGildings20m  maxNumGildings21_40m  maxNumGildings41_60m  maxScoreGrowth21_40m41_60m  maxNumCommentsGrowth21_40m41_60m  predict_proba_1  stepUp\n",
      "0  1234567      pics  Test1 2023-04-19 03:14:30            0               0              21                  0                     0                     1               0.00                  0.00                  0.97                  0                     0                     0                         0.0                               0.0         0.023970       0\n",
      "1  1234568      pics  Test2 2023-04-20 03:14:30           10              29              67                  1                     6                     9               0.95                  0.95                  0.94                  0                     0                     0                         1.1                               0.5         0.048071       1\n",
      "2  1234569      pics  Test3 2023-04-20 03:14:30           10              29             150                  1                     6                    20               0.95                  0.95                  0.94                  0                     0                     0                         1.1                               0.5         0.122288       1\n",
      "Data count after filtering existing data: 3\n",
      "Writing to postgres\n",
      "        subreddit  title        createdTSUTC  maxScore20m  maxScore21_40m  \\\n",
      "postId                                                                      \n",
      "1234567      pics  Test1 2023-04-19 03:14:30            0               0   \n",
      "1234568      pics  Test2 2023-04-20 03:14:30           10              29   \n",
      "1234569      pics  Test3 2023-04-20 03:14:30           10              29   \n",
      "\n",
      "         maxScore41_60m  maxNumComments20m  maxNumComments21_40m  \\\n",
      "postId                                                             \n",
      "1234567              21                  0                     0   \n",
      "1234568              67                  1                     6   \n",
      "1234569             150                  1                     6   \n",
      "\n",
      "         maxNumComments41_60m  maxUpvoteRatio20m  maxUpvoteRatio21_40m  \\\n",
      "postId                                                                   \n",
      "1234567                     1               0.00                  0.00   \n",
      "1234568                     9               0.95                  0.95   \n",
      "1234569                    20               0.95                  0.95   \n",
      "\n",
      "         maxUpvoteRatio41_60m  maxNumGildings20m  maxNumGildings21_40m  \\\n",
      "postId                                                                   \n",
      "1234567                  0.97                  0                     0   \n",
      "1234568                  0.94                  0                     0   \n",
      "1234569                  0.94                  0                     0   \n",
      "\n",
      "         maxNumGildings41_60m  maxScoreGrowth21_40m41_60m  \\\n",
      "postId                                                      \n",
      "1234567                     0                         0.0   \n",
      "1234568                     0                         1.1   \n",
      "1234569                     0                         1.1   \n",
      "\n",
      "         maxNumCommentsGrowth21_40m41_60m  predict_proba_1  stepUp  \n",
      "postId                                                              \n",
      "1234567                               0.0         0.023970       0  \n",
      "1234568                               0.5         0.048071       1  \n",
      "1234569                               0.5         0.122288       1  \n",
      "Finished writing to postgres\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# originally was defining here but later moved to python file\n",
    "from PredictETL import Pipeline\n",
    "from tests import testPipeline\n",
    "\n",
    "testPipeline(model, spark, threshold=0.0400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T22:05:33.235922Z",
     "start_time": "2023-04-24T22:05:31.173878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed upsert test\n"
     ]
    }
   ],
   "source": [
    "# testing upsert with a simple example\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import sqlUtils as su\n",
    "\n",
    "indexes = [\"id1\",\"id2\"]\n",
    "testDf  = pd.DataFrame(\n",
    "  {\n",
    "    \"id1\": [1, 2, 3, 4, 5],\n",
    "    \"id2\": [\"a\", \"a\", \"b\", \"c\", \"d\"],\n",
    "    \"name\": [\"surname1\", \"surname2\", \"surname3\", \"name4\", \"dname\"],\n",
    "    \"age\": [13, 44, 29, 68, 100],\n",
    "  }\n",
    ").set_index(indexes)\n",
    "\n",
    "engine = create_engine(f\"postgresql+pg8000://{cfg['USERNAME']}:{cfg['PASSWORD']}@{cfg['HOST']}:{cfg['PORT']}/{cfg['DATABASE']}\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "  result = su.upsert_df(df=testDf, table_name='test_upsert_table', engine=conn)\n",
    "  print('completed upsert test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "209.833px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
